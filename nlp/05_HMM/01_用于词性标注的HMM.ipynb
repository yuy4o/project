{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 词性标注\n",
    "\n",
    "使用nltk自带的Brown词库进行学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入所需要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sys\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预处理词库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('The', 'AT'),\n",
       "  ('Fulton', 'NP-TL'),\n",
       "  ('County', 'NN-TL'),\n",
       "  ('Grand', 'JJ-TL'),\n",
       "  ('Jury', 'NN-TL'),\n",
       "  ('said', 'VBD'),\n",
       "  ('Friday', 'NR'),\n",
       "  ('an', 'AT'),\n",
       "  ('investigation', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  (\"Atlanta's\", 'NP$'),\n",
       "  ('recent', 'JJ'),\n",
       "  ('primary', 'NN'),\n",
       "  ('election', 'NN'),\n",
       "  ('produced', 'VBD'),\n",
       "  ('``', '``'),\n",
       "  ('no', 'AT'),\n",
       "  ('evidence', 'NN'),\n",
       "  (\"''\", \"''\"),\n",
       "  ('that', 'CS'),\n",
       "  ('any', 'DTI'),\n",
       "  ('irregularities', 'NNS'),\n",
       "  ('took', 'VBD'),\n",
       "  ('place', 'NN'),\n",
       "  ('.', '.')],\n",
       " [('The', 'AT'),\n",
       "  ('jury', 'NN'),\n",
       "  ('further', 'RBR'),\n",
       "  ('said', 'VBD'),\n",
       "  ('in', 'IN'),\n",
       "  ('term-end', 'NN'),\n",
       "  ('presentments', 'NNS'),\n",
       "  ('that', 'CS'),\n",
       "  ('the', 'AT'),\n",
       "  ('City', 'NN-TL'),\n",
       "  ('Executive', 'JJ-TL'),\n",
       "  ('Committee', 'NN-TL'),\n",
       "  (',', ','),\n",
       "  ('which', 'WDT'),\n",
       "  ('had', 'HVD'),\n",
       "  ('over-all', 'JJ'),\n",
       "  ('charge', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('the', 'AT'),\n",
       "  ('election', 'NN'),\n",
       "  (',', ','),\n",
       "  ('``', '``'),\n",
       "  ('deserves', 'VBZ'),\n",
       "  ('the', 'AT'),\n",
       "  ('praise', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('thanks', 'NNS'),\n",
       "  ('of', 'IN'),\n",
       "  ('the', 'AT'),\n",
       "  ('City', 'NN-TL'),\n",
       "  ('of', 'IN-TL'),\n",
       "  ('Atlanta', 'NP-TL'),\n",
       "  (\"''\", \"''\"),\n",
       "  ('for', 'IN'),\n",
       "  ('the', 'AT'),\n",
       "  ('manner', 'NN'),\n",
       "  ('in', 'IN'),\n",
       "  ('which', 'WDT'),\n",
       "  ('the', 'AT'),\n",
       "  ('election', 'NN'),\n",
       "  ('was', 'BEDZ'),\n",
       "  ('conducted', 'VBN'),\n",
       "  ('.', '.')]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看数据\n",
    "brown.tagged_sents()[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由上可知，Brown里面的句子都是自己标注好了的，长这个样子：\n",
    "\n",
    "    [[('The', 'AT'), ('said', 'VBD'),..., ('that', 'CS')],[],...,[]]\n",
    "\n",
    "里面的每一个[]表示一个样本\n",
    "\n",
    "我们需要做的就是：给词加上开始和结束符号，因此我们加的格式要和上面的格式一样\n",
    "\n",
    "这里我们使用：\n",
    "\n",
    "(START,START)(END,END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_tags_words = [ ]\n",
    "for sent in brown.tagged_sents():\n",
    "    # 先加开头\n",
    "    brown_tags_words.append( (\"START\", \"START\") )\n",
    "    # 为了省事儿，我们把tag都省略成前两个字母\n",
    "    brown_tags_words.extend([ (tag[:2], word) for (word, tag) in sent ])\n",
    "    # 加个结尾\n",
    "    brown_tags_words.append( (\"END\", \"END\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('START', 'START'),\n",
       " ('AT', 'The'),\n",
       " ('NP', 'Fulton'),\n",
       " ('NN', 'County'),\n",
       " ('JJ', 'Grand'),\n",
       " ('NN', 'Jury'),\n",
       " ('VB', 'said'),\n",
       " ('NR', 'Friday'),\n",
       " ('AT', 'an'),\n",
       " ('NN', 'investigation'),\n",
       " ('IN', 'of'),\n",
       " ('NP', \"Atlanta's\"),\n",
       " ('JJ', 'recent'),\n",
       " ('NN', 'primary'),\n",
       " ('NN', 'election'),\n",
       " ('VB', 'produced'),\n",
       " ('``', '``'),\n",
       " ('AT', 'no'),\n",
       " ('NN', 'evidence'),\n",
       " (\"''\", \"''\"),\n",
       " ('CS', 'that'),\n",
       " ('DT', 'any'),\n",
       " ('NN', 'irregularities'),\n",
       " ('VB', 'took'),\n",
       " ('NN', 'place'),\n",
       " ('.', '.'),\n",
       " ('END', 'END'),\n",
       " ('START', 'START'),\n",
       " ('AT', 'The'),\n",
       " ('NN', 'jury'),\n",
       " ('RB', 'further'),\n",
       " ('VB', 'said'),\n",
       " ('IN', 'in'),\n",
       " ('NN', 'term-end'),\n",
       " ('NN', 'presentments'),\n",
       " ('CS', 'that'),\n",
       " ('AT', 'the'),\n",
       " ('NN', 'City'),\n",
       " ('JJ', 'Executive'),\n",
       " ('NN', 'Committee'),\n",
       " (',', ','),\n",
       " ('WD', 'which'),\n",
       " ('HV', 'had'),\n",
       " ('JJ', 'over-all'),\n",
       " ('NN', 'charge'),\n",
       " ('IN', 'of'),\n",
       " ('AT', 'the'),\n",
       " ('NN', 'election'),\n",
       " (',', ','),\n",
       " ('``', '``')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 也就是将上面的里面的[]换成一对('START', 'START')、('END', 'END')\n",
    "# 处理完：[('START', 'START'),('AT', 'The'), ('VB', 'said'),..., ('CS', 'that'),('END', 'END'),('START', 'START'),...,('END', 'END'),...,('START', 'START'),...,('END', 'END')]\n",
    "brown_tags_words[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 词统计\n",
    "\n",
    "我们要把我们所有的词库中拥有的单词与tag之间的关系，做个简单粗暴的统计。\n",
    "\n",
    "$$P(w_i | t_i) = \\frac{count(w_i,t_i)}{count(t_i)}$$\n",
    "\n",
    "这里NLTK给了我们做统计的工具，也可以自行实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 条件频率分布\n",
    "cfd_tagwords = nltk.ConditionalFreqDist(brown_tags_words)\n",
    "# 条件概率分布\n",
    "cpd_tagwords = nltk.ConditionalProbDist(cfd_tagwords, nltk.MLEProbDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of an adjective (JJ) being 'new' is 0.01472344917632025\n",
      "The probability of a verb (VB) being 'duck' is 6.042713350943527e-05\n"
     ]
    }
   ],
   "source": [
    "# 看看统计结果\n",
    "print(\"The probability of an adjective (JJ) being 'new' is\", cpd_tagwords[\"JJ\"].prob(\"new\"))\n",
    "print(\"The probability of a verb (VB) being 'duck' is\", cpd_tagwords[\"VB\"].prob(\"duck\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(t_i|t_{i-1})=\\frac{count(t_{i-1},t_i)}{count(t_{i-1})}$$\n",
    "\n",
    "这个公式跟words没有什么关系。它是属于隐层的马尔可夫链。所以我们先取出所有的tag来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_tags = [tag for (tag, word) in brown_tags_words ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count(t{i-1} ti)\n",
    "# bigram的意思是 前后两个一组，联在一起\n",
    "cfd_tags= nltk.ConditionalFreqDist(nltk.bigrams(brown_tags))\n",
    "# P(ti | t{i-1})\n",
    "cpd_tags = nltk.ConditionalProbDist(cfd_tags, nltk.MLEProbDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If we have just seen 'DT', the probability of 'NN' is 0.5057722522030194\n",
      "If we have just seen 'VB', the probability of 'JJ' is 0.016885067592065053\n",
      "If we have just seen 'VB', the probability of 'NN' is 0.10970977711020183\n"
     ]
    }
   ],
   "source": [
    "print(\"If we have just seen 'DT', the probability of 'NN' is\", cpd_tags[\"DT\"].prob(\"NN\"))\n",
    "print( \"If we have just seen 'VB', the probability of 'JJ' is\", cpd_tags[\"VB\"].prob(\"DT\"))\n",
    "print( \"If we have just seen 'VB', the probability of 'NN' is\", cpd_tags[\"VB\"].prob(\"NN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们有一句话，\"I want to race\"， 一套tag，\"PP VB TO VB\"，那么他们之间的匹配度有多高呢？\n",
    "\n",
    "其实就是：\n",
    "\n",
    "$$P(START)*P(PP|START)*P(I|PP)*P(VB|PP)*P(want|VB)*P(TO | VB)\\\\\n",
    "* P(to | TO) *P(VB | TO) * P(race | VB)*P(END | VB)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of the tag sequence 'START PP VB TO VB END' for 'I want to race' is: 1.0817766461150474e-14\n"
     ]
    }
   ],
   "source": [
    "prob_tagsequence = cpd_tags[\"START\"].prob(\"PP\") * cpd_tagwords[\"PP\"].prob(\"I\") * \\\n",
    "    cpd_tags[\"PP\"].prob(\"VB\") * cpd_tagwords[\"VB\"].prob(\"want\") * \\\n",
    "    cpd_tags[\"VB\"].prob(\"TO\") * cpd_tagwords[\"TO\"].prob(\"to\") * \\\n",
    "    cpd_tags[\"TO\"].prob(\"VB\") * cpd_tagwords[\"VB\"].prob(\"race\") * \\\n",
    "    cpd_tags[\"VB\"].prob(\"END\")\n",
    "\n",
    "print( \"The probability of the tag sequence 'START PP VB TO VB END' for 'I want to race' is:\", prob_tagsequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viterbi 的实现\n",
    "\n",
    "如果我们手上有一句话，怎么知道最符合的tag是哪组呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先，我们拿出所有独特的tags（也就是tags的全集）\n",
    "distinct_tags = set(brown_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 给定一句话\n",
    "sentence = [\"I\", \"want\", \"to\", \"race\" ]\n",
    "sentlen = len(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EX': 0.0, 'HV': 0.0, '*': 0.0, 'BE': 0.0, 'NR': 0.0, 'WP': 0.0, 'RP': 0.0, 'CC': 0.0, 'UH': 0.0, ')-': 0.0, 'FW': 0.0, 'AP': 0.0, '.-': 0.0, 'AB': 0.0, ',-': 0.0, '--': 0.0, 'WR': 0.0, ':-': 0.0, 'RB': 0.0, 'VB': 0.0, 'NP': 1.7319067623793952e-06, 'PN': 0.0, 'QL': 0.0, 'WQ': 0.0, 'TO': 0.0, 'DO': 0.0, \"''\": 0.0, 'DT': 0.0, 'RN': 0.0, ',': 0.0, 'NI': 3.3324520848931064e-07, ')': 0.0, ':': 0.0, 'OD': 0.0, 'AT': 0.0, 'WD': 0.0, 'CS': 0.0, 'PP': 0.014930900689060006, 'IN': 0.0, 'END': 0.0, '*-': 0.0, 'NN': 1.0580313619573935e-06, '(': 0.0, '.': 0.0, 'JJ': 0.0, '``': 0.0, '(-': 0.0, \"'\": 0.0, 'MD': 0.0, 'CD': 0.0}\n",
      "{'EX': 'START', 'HV': 'START', '*': 'START', 'BE': 'START', 'NR': 'START', 'WP': 'START', 'RP': 'START', 'CC': 'START', 'UH': 'START', ')-': 'START', 'FW': 'START', 'AP': 'START', '.-': 'START', 'AB': 'START', ',-': 'START', '--': 'START', 'WR': 'START', ':-': 'START', 'RB': 'START', 'VB': 'START', 'NP': 'START', 'PN': 'START', 'QL': 'START', 'WQ': 'START', 'TO': 'START', 'DO': 'START', \"''\": 'START', 'DT': 'START', 'RN': 'START', ',': 'START', 'NI': 'START', ')': 'START', ':': 'START', 'OD': 'START', 'AT': 'START', 'WD': 'START', 'CS': 'START', 'PP': 'START', 'IN': 'START', 'END': 'START', '*-': 'START', 'NN': 'START', '(': 'START', '.': 'START', 'JJ': 'START', '``': 'START', '(-': 'START', \"'\": 'START', 'MD': 'START', 'CD': 'START'}\n"
     ]
    }
   ],
   "source": [
    "# 开始维特比，从1循环到句子的总长N，记为i；每次都找出以tag X为最终节点，长度为i的tag链\n",
    "viterbi = [ ]\n",
    "# 同时，还需要一个回溯器，从1循环到句子的总长N，记为i；把所有的tag X前一个tag记下来\n",
    "backpointer = [ ]\n",
    "\n",
    "first_viterbi = { }\n",
    "first_backpointer = { }\n",
    "for tag in distinct_tags:\n",
    "    # 不要为START标签记录任何内容\n",
    "    if tag == \"START\": continue\n",
    "    first_viterbi[ tag ] = cpd_tags[\"START\"].prob(tag) * cpd_tagwords[tag].prob( sentence[0] )\n",
    "    first_backpointer[ tag ] = \"START\"\n",
    "\n",
    "print(first_viterbi)\n",
    "print(first_backpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以上，是所有的第一个viterbi 和第一个回溯点。存到vitterbi和backpointer两个变量里去\n",
    "viterbi.append(first_viterbi)\n",
    "backpointer.append(first_backpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 'I' current best two-tag sequence: START PP\n"
     ]
    }
   ],
   "source": [
    "# 看一看目前最好的tag是啥\n",
    "currbest = max(first_viterbi.keys(), key = lambda tag: first_viterbi[ tag ])\n",
    "print( \"Word\", \"'\" + sentence[0] + \"'\", \"current best two-tag sequence:\", first_backpointer[ currbest], currbest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 'want' current best two-tag sequence: PP VB\n",
      "Word 'to' current best two-tag sequence: VB TO\n",
      "Word 'race' current best two-tag sequence: IN NN\n"
     ]
    }
   ],
   "source": [
    "# 开始回溯\n",
    "for wordindex in range(1, len(sentence)):\n",
    "    this_viterbi = { }\n",
    "    this_backpointer = { }\n",
    "    prev_viterbi = viterbi[-1]\n",
    "    \n",
    "    for tag in distinct_tags:\n",
    "        # START没啥用，可忽略\n",
    "        if tag == \"START\": continue\n",
    "        \n",
    "        # 如果现在这个tag是X，现在的单词是w，\n",
    "        # 我们想找前一个tag Y，并且让最好的tag sequence以Y X结尾。\n",
    "        # 也就是说\n",
    "        # Y要能最大化：\n",
    "        # prev_viterbi[ Y ] * P(X | Y) * P( w | X)\n",
    "        \n",
    "        best_previous = max(prev_viterbi.keys(),\n",
    "                            key = lambda prevtag: \\\n",
    "            prev_viterbi[ prevtag ] * cpd_tags[prevtag].prob(tag) * cpd_tagwords[tag].prob(sentence[wordindex]))\n",
    "\n",
    "        this_viterbi[ tag ] = prev_viterbi[ best_previous] * \\\n",
    "            cpd_tags[ best_previous ].prob(tag) * cpd_tagwords[ tag].prob(sentence[wordindex])\n",
    "        this_backpointer[ tag ] = best_previous\n",
    "    \n",
    "    # 每次找完Y 我们把目前最好的 存一下\n",
    "    currbest = max(this_viterbi.keys(), key = lambda tag: this_viterbi[ tag ])\n",
    "    print( \"Word\", \"'\" + sentence[ wordindex] + \"'\", \"current best two-tag sequence:\", this_backpointer[ currbest], currbest)\n",
    "\n",
    "\n",
    "    # 完结\n",
    "    # 全部存下来\n",
    "    viterbi.append(this_viterbi)\n",
    "    backpointer.append(this_backpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找END，结束\n",
    "# 找所有以END结尾的tag sequence\n",
    "prev_viterbi = viterbi[-1]\n",
    "best_previous = max(prev_viterbi.keys(),\n",
    "                    key = lambda prevtag: prev_viterbi[ prevtag ] * cpd_tags[prevtag].prob(\"END\"))\n",
    "\n",
    "prob_tagsequence = prev_viterbi[ best_previous ] * cpd_tags[ best_previous].prob(\"END\")\n",
    "\n",
    "# 我们这会儿是倒着存的，因为好的在后面\n",
    "best_tagsequence = [ \"END\", best_previous ]\n",
    "# 同理 这里也有倒过来\n",
    "backpointer.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 回溯所有的回溯点，此时，最好的tag就是backpointer里面的current best\n",
    "current_best_tag = best_previous\n",
    "for bp in backpointer:\n",
    "    best_tagsequence.append(bp[current_best_tag])\n",
    "    current_best_tag = bp[current_best_tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence was: I want to race \n",
      "\n",
      "The best tag sequence is: START PP VB IN NN END \n",
      "\n",
      "The probability of the best tag sequence is: 5.71772824864617e-14\n"
     ]
    }
   ],
   "source": [
    "# 显示结果\n",
    "best_tagsequence.reverse()\n",
    "print( \"The sentence was:\", end = \" \")\n",
    "for w in sentence: print( w, end = \" \")\n",
    "print(\"\\n\")\n",
    "print( \"The best tag sequence is:\", end = \" \")\n",
    "for t in best_tagsequence: print (t, end = \" \")\n",
    "print(\"\\n\")\n",
    "print( \"The probability of the best tag sequence is:\", prob_tagsequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

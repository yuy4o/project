{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入第三方库\n",
    "import pkuseg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['北京', '大学', '和', '清华', '大学', '都', '在', '北京']\n"
     ]
    }
   ],
   "source": [
    "# 示例1：使用默认模型及默认词典分词\n",
    "seg = pkuseg.pkuseg()  # 以默认配置加载模型\n",
    "text = seg.cut('北京大学和清华大学都在北京')  # 进行分词\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['北京大学', '和', '清华大学', '都', '在', '北京']\n"
     ]
    }
   ],
   "source": [
    "# 示例2：设置用户自定义词典\n",
    "import pkuseg\n",
    "myDict = ['北京大学','清华大学']  # 用户自定义的词典中的词在分词的时候不分开\n",
    "seg = pkuseg.pkuseg(user_dict = myDict)  # 加载模型，并给定用户自定义词典\n",
    "text = seg.cut('北京大学和清华大学都在北京')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/lancopku/pkuseg-python/releases/download/v0.0.16/medicine.zip\" to C:\\Users\\lenovo/.pkuseg\\medicine.zip\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['北京大学', '和', '清华大学', '都', '在', '北京']\n"
     ]
    }
   ],
   "source": [
    "# 示例3：细领域分词，如果用户明确分词领域，推荐使用细领域模型分词\n",
    "import pkuseg\n",
    "seg = pkuseg.pkuseg(model_name='medicine')  # 程序会自动下载所对应的细领域模型\n",
    "text = seg.cut('北京大学和清华大学都在北京')  # 进行分词\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/lancopku/pkuseg-python/releases/download/v0.0.16/postag.zip\" to C:\\Users\\lenovo/.pkuseg\\postag.zip\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('北京', 'ns'), ('大学', 'n'), ('和', 'c'), ('清华', 'j'), ('大学', 'n'), ('都', 'd'), ('在', 'v'), ('北京', 'ns')]\n"
     ]
    }
   ],
   "source": [
    "# 示例4：分词同时进行词性标注\n",
    "import pkuseg\n",
    "seg = pkuseg.pkuseg(postag=True)  # 开启词性标注功能\n",
    "text = seg.cut('北京大学和清华大学都在北京')  # 进行分词和词性标注\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 词性表\n",
    "    n   名词\n",
    "    t   时间词\n",
    "    s   处所词\n",
    "    f   方位词\n",
    "    m   数词\n",
    "    q   量词\n",
    "    b   区别词\n",
    "    r   代词\n",
    "    v   动词\n",
    "    a   形容词\n",
    "    z   状态词\n",
    "    d   副词\n",
    "    p   介词\n",
    "    c   连词\n",
    "    u   助词\n",
    "    y   语气词\n",
    "    e   叹词\n",
    "    o   拟声词\n",
    "    i   成语\n",
    "    l   习惯用语\n",
    "    j   简称\n",
    "    h   前接成分\n",
    "    k   后接成分\n",
    "    g   语素\n",
    "    x   非语素字\n",
    "    w   标点符号\n",
    "    nr  人名\n",
    "    ns  地名\n",
    "    nt  机构名称\n",
    "    nx  外文字符\n",
    "    nz  其它专名\n",
    "    vd  副动词\n",
    "    vn  名动词\n",
    "    vx  形式动词\n",
    "    ad  副形词\n",
    "    an  名形词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_time:\t45.956\n"
     ]
    }
   ],
   "source": [
    "# 示例5：对文件进行分词\n",
    "import pkuseg\n",
    "\n",
    "# 对input.txt的文件分词输出到output.txt中\n",
    "# 开20个进程\n",
    "pkuseg.test('NBA.txt', 'output.txt', nthread=20)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['北京大学', '和', '清华大学', '都在', '北京']\n"
     ]
    }
   ],
   "source": [
    "# 示例5：额外使用用户自定义词典\n",
    "import pkuseg\n",
    "\n",
    "seg = pkuseg.pkuseg(user_dict='my_dict.txt')  # 给定用户词典为当前目录下的\"my_dict.txt\"\n",
    "text = seg.cut('北京大学和清华大学都在北京')                # 进行分词\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['北京大学', '和', '清华大学', '都', '在', '北京']\n"
     ]
    }
   ],
   "source": [
    "# 示例6：使用自训练模型分词（以CTB8模型为例）\n",
    "import pkuseg\n",
    "\n",
    "# seg = pkuseg.pkuseg(model_name='./ctb8')  # 假设用户已经下载好了ctb8的模型并放在了'./ctb8'目录下，通过设置model_name加载该模型\n",
    "seg = pkuseg.pkuseg(model_name='./msra')\n",
    "# seg = pkuseg.pkuseg(model_name='./weibo')\n",
    "text = seg.cut('北京大学和清华大学都在北京')            # 进行分词\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例7：训练新模型（模型随机初始化）\n",
    "import pkuseg\n",
    "\n",
    "# 训练文件为'msr_training.utf8'\n",
    "# 测试文件为'msr_test_gold.utf8'\n",
    "# 训练好的模型存到'./models'目录下\n",
    "# 训练模式下会保存最后一轮模型作为最终模型\n",
    "# 目前仅支持utf-8编码，训练集和测试集要求所有单词以单个或多个空格分开\n",
    "\n",
    "# pkuseg.train('msr_training.utf8', 'msr_test_gold.utf8', './models')\n",
    "# 此处就不就训练了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例8：fine-tune训练（从预加载的模型继续训练）\n",
    "import pkuseg\n",
    "\n",
    "# 训练文件为'train.txt'\n",
    "# 测试文件为'test.txt'\n",
    "# 加载'./pretrained'目录下的模型，训练好的模型保存在'./models'，训练10轮\n",
    "# pkuseg.train('train.txt', 'test.txt', './models', train_iter=10, init_model='./pretrained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
